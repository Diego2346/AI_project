{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PIX2PIX-Facades.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqqfGsEcfB5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5140a9d5-f2ca-4ffa-d152-1800d61e85b0"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import argparse\n",
        "import math\n",
        "import itertools\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "URL = 'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz'\n",
        "path_to_zip = tf.keras.utils.get_file('facades.tar.gz',origin=URL,extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
            "30171136/30168306 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jfjw3fqenPk"
      },
      "source": [
        "**DATASET**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjP4qFqGelIc"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, mode=\"train\"):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.files = sorted(glob.glob(os.path.join(root, mode) + \"/*.*\"))\n",
        "        if mode == \"train\":\n",
        "            self.files.extend(sorted(glob.glob(os.path.join(root, \"test\") + \"/*.*\")))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index % len(self.files)])\n",
        "        w, h = img.size\n",
        "        img_A = img.crop((0, 0, w / 2, h))\n",
        "        img_B = img.crop((w / 2, 0, w, h))\n",
        "\n",
        "        if np.random.random() < 0.5:\n",
        "            img_A = Image.fromarray(np.array(img_A)[:, ::-1, :], \"RGB\")\n",
        "            img_B = Image.fromarray(np.array(img_B)[:, ::-1, :], \"RGB\")\n",
        "\n",
        "        img_A = self.transform(img_A)\n",
        "        img_B = self.transform(img_B)\n",
        "\n",
        "        return {\"A\": img_A, \"B\": img_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl2pZ4kRel5s"
      },
      "source": [
        "**MODELS**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMvaAnwGe6Uk"
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "##############################\n",
        "#           U-NET\n",
        "##############################\n",
        "\n",
        "\n",
        "class UNetDown(nn.Module):\n",
        "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
        "        super(UNetDown, self).__init__()\n",
        "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
        "        if normalize:\n",
        "            layers.append(nn.InstanceNorm2d(out_size))\n",
        "        layers.append(nn.LeakyReLU(0.2))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, in_size, out_size, dropout=0.0):\n",
        "        super(UNetUp, self).__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(out_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        x = self.model(x)\n",
        "        x = torch.cat((x, skip_input), 1)\n",
        "\n",
        "        return x\n",
        "  \n",
        "\n",
        "class GeneratorUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super(GeneratorUNet, self).__init__()\n",
        "\n",
        "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
        "        self.down2 = UNetDown(64, 128)\n",
        "        self.down3 = UNetDown(128, 256)\n",
        "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
        "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
        "\n",
        "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
        "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up5 = UNetUp(1024, 256)\n",
        "        self.up6 = UNetUp(512, 128)\n",
        "        self.up7 = UNetUp(256, 64)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # U-Net generator with skip connections from encoder to decoder\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "        d7 = self.down7(d6)\n",
        "        d8 = self.down8(d7)\n",
        "        u1 = self.up1(d8, d7)\n",
        "        u2 = self.up2(u1, d6)\n",
        "        u3 = self.up3(u2, d5)\n",
        "        u4 = self.up4(u3, d4)\n",
        "        u5 = self.up5(u4, d3)\n",
        "        u6 = self.up6(u5, d2)\n",
        "        u7 = self.up7(u6, d1)\n",
        "\n",
        "        return self.final(u7)\n",
        "\n",
        "\n",
        "##############################\n",
        "#        Discriminator\n",
        "##############################\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalization:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        img_input = torch.cat((img_A, img_B), 1)\n",
        "        return self.model(img_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9x-Sxzse6HZ"
      },
      "source": [
        "***CONFIGURATION***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYPOO5UTfIEt",
        "outputId": "fdbe269b-783c-43ea-fd25-08a40c5c6ac6"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument(\"--epoch\", type=int, default=0, help=\"epoch to start training from\")\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")  \n",
        "parser.add_argument(\"--dataset_name\", type=str, default=\"facades\", help=\"name of the dataset\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=1, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--decay_epoch\", type=int, default=100, help=\"epoch from which to start lr decay\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=2, help=\"number of cpu threads to use during batch generation\") #8\n",
        "parser.add_argument(\"--img_height\", type=int, default=256, help=\"size of image height\")\n",
        "parser.add_argument(\"--img_width\", type=int, default=256, help=\"size of image width\")\n",
        "parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=500, help=\"interval between sampling of images from generators\")\n",
        "parser.add_argument(\"--checkpoint_interval\", type=int, default=-1, help=\"interval between model checkpoints\")\n",
        "opt = parser.parse_args()\n",
        "print(opt)\n",
        "\n",
        "os.makedirs(\"images/%s\" % opt.dataset_name, exist_ok=True)\n",
        "os.makedirs(\"saved_models/%s\" % opt.dataset_name, exist_ok=True)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "# Loss functions\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_pixelwise = torch.nn.L1Loss()\n",
        "\n",
        "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
        "lambda_pixel = 100\n",
        "\n",
        "# Calculate output of image discriminator (PatchGAN)\n",
        "patch = (1, opt.img_height // 2 ** 4, opt.img_width // 2 ** 4)\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = GeneratorUNet()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_pixelwise.cuda()\n",
        "\n",
        "if opt.epoch != 0:\n",
        "    # Load pretrained models\n",
        "    generator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "    discriminator.load_state_dict(torch.load(\"saved_models/%s/discriminator_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
        "else:\n",
        "    # Initialize weights\n",
        "    generator.apply(weights_init_normal)\n",
        "    discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "# Configure dataloaders\n",
        "transforms_ = [\n",
        "    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(PATH, transforms_=transforms_),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu,\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(PATH, transforms_=transforms_, mode=\"val\"),\n",
        "    batch_size=10,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "# Tensor type\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "\n",
        "def sample_images(batches_done):\n",
        "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    real_A = Variable(imgs[\"B\"].type(Tensor))\n",
        "    real_B = Variable(imgs[\"A\"].type(Tensor))\n",
        "    fake_B = generator(real_A)\n",
        "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
        "    save_image(img_sample, \"images/%s/%s.png\" % (opt.dataset_name, batches_done), nrow=5, normalize=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(b1=0.5, b2=0.999, batch_size=1, channels=3, checkpoint_interval=-1, dataset_name='facades', decay_epoch=100, epoch=0, f='/root/.local/share/jupyter/runtime/kernel-6fd19b5a-0892-413f-a2e2-dbfc3cf107a6.json', img_height=256, img_width=256, lr=0.0002, n_cpu=2, n_epochs=200, sample_interval=500)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SgFnXO4qdQE",
        "outputId": "fb775630-c8e0-465f-ce42-e8c156b21844"
      },
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "prev_time = time.time()\n",
        "\n",
        "for epoch in range(opt.epoch, opt.n_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Model inputs\n",
        "        real_A = Variable(batch[\"B\"].type(Tensor))\n",
        "        real_B = Variable(batch[\"A\"].type(Tensor))\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = generator(real_A)\n",
        "        pred_fake = discriminator(fake_B, real_A)\n",
        "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
        "        # Pixel-wise loss\n",
        "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
        "\n",
        "        loss_G.backward()\n",
        "\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = discriminator(real_B, real_A)\n",
        "        loss_real = criterion_GAN(pred_real, valid)\n",
        "\n",
        "        # Fake loss\n",
        "        pred_fake = discriminator(fake_B.detach(), real_A)\n",
        "        loss_fake = criterion_GAN(pred_fake, fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D = 0.5 * (loss_real + loss_fake)\n",
        "\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # --------------\n",
        "        #  Log Progress\n",
        "        # --------------\n",
        "\n",
        "        # Determine approximate time left\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = opt.n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "\n",
        "        # Print log\n",
        "        sys.stdout.write(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, adv: %f] ETA: %s\"\n",
        "            % (\n",
        "                epoch,\n",
        "                opt.n_epochs,\n",
        "                i,\n",
        "                len(dataloader),\n",
        "                loss_D.item(),\n",
        "                loss_G.item(),\n",
        "                loss_pixel.item(),\n",
        "                loss_GAN.item(),\n",
        "                time_left,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # If at sample interval save image\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            sample_images(batches_done)\n",
        "\n",
        "    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
        "        # Save model checkpoints\n",
        "        torch.save(generator.state_dict(), \"saved_models/%s/generator_%d.pth\" % (opt.dataset_name, epoch))\n",
        "        torch.save(discriminator.state_dict(), \"saved_models/%s/discriminator_%d.pth\" % (opt.dataset_name, epoch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 199/200] [Batch 505/506] [D loss: 0.000752] [G loss: 16.011837, pixel: 0.150567, adv: 0.955111] ETA: 0:00:00.070618"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru4RywYD5DgB"
      },
      "source": [
        "Download output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K8vJAspj4iVO",
        "outputId": "2742ce80-a3d3-4786-a9a7-946b6002c3ec"
      },
      "source": [
        "!zip -r /content/file.zip /content/images\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/images/ (stored 0%)\n",
            "  adding: content/images/facades/ (stored 0%)\n",
            "  adding: content/images/facades/81500.png (deflated 0%)\n",
            "  adding: content/images/facades/95500.png (deflated 0%)\n",
            "  adding: content/images/facades/37000.png (deflated 0%)\n",
            "  adding: content/images/facades/24500.png (deflated 0%)\n",
            "  adding: content/images/facades/68500.png (deflated 0%)\n",
            "  adding: content/images/facades/94000.png (deflated 0%)\n",
            "  adding: content/images/facades/84500.png (deflated 0%)\n",
            "  adding: content/images/facades/54000.png (deflated 0%)\n",
            "  adding: content/images/facades/9000.png (deflated 0%)\n",
            "  adding: content/images/facades/89000.png (deflated 0%)\n",
            "  adding: content/images/facades/89500.png (deflated 0%)\n",
            "  adding: content/images/facades/66500.png (deflated 0%)\n",
            "  adding: content/images/facades/36000.png (deflated 0%)\n",
            "  adding: content/images/facades/78000.png (deflated 0%)\n",
            "  adding: content/images/facades/76500.png (deflated 0%)\n",
            "  adding: content/images/facades/39000.png (deflated 0%)\n",
            "  adding: content/images/facades/44000.png (deflated 0%)\n",
            "  adding: content/images/facades/92500.png (deflated 0%)\n",
            "  adding: content/images/facades/17000.png (deflated 0%)\n",
            "  adding: content/images/facades/23500.png (deflated 0%)\n",
            "  adding: content/images/facades/80000.png (deflated 0%)\n",
            "  adding: content/images/facades/31500.png (deflated 0%)\n",
            "  adding: content/images/facades/67000.png (deflated 0%)\n",
            "  adding: content/images/facades/60500.png (deflated 0%)\n",
            "  adding: content/images/facades/6000.png (deflated 0%)\n",
            "  adding: content/images/facades/38000.png (deflated 0%)\n",
            "  adding: content/images/facades/20000.png (deflated 0%)\n",
            "  adding: content/images/facades/79500.png (deflated 0%)\n",
            "  adding: content/images/facades/55000.png (deflated 0%)\n",
            "  adding: content/images/facades/21500.png (deflated 0%)\n",
            "  adding: content/images/facades/49500.png (deflated 0%)\n",
            "  adding: content/images/facades/84000.png (deflated 0%)\n",
            "  adding: content/images/facades/15000.png (deflated 0%)\n",
            "  adding: content/images/facades/13500.png (deflated 0%)\n",
            "  adding: content/images/facades/46000.png (deflated 0%)\n",
            "  adding: content/images/facades/33500.png (deflated 0%)\n",
            "  adding: content/images/facades/73500.png (deflated 0%)\n",
            "  adding: content/images/facades/52500.png (deflated 0%)\n",
            "  adding: content/images/facades/31000.png (deflated 0%)\n",
            "  adding: content/images/facades/100000.png (deflated 0%)\n",
            "  adding: content/images/facades/61500.png (deflated 0%)\n",
            "  adding: content/images/facades/14500.png (deflated 0%)\n",
            "  adding: content/images/facades/18500.png (deflated 0%)\n",
            "  adding: content/images/facades/24000.png (deflated 0%)\n",
            "  adding: content/images/facades/41000.png (deflated 0%)\n",
            "  adding: content/images/facades/48500.png (deflated 0%)\n",
            "  adding: content/images/facades/82500.png (deflated 0%)\n",
            "  adding: content/images/facades/64500.png (deflated 0%)\n",
            "  adding: content/images/facades/35000.png (deflated 0%)\n",
            "  adding: content/images/facades/25000.png (deflated 0%)\n",
            "  adding: content/images/facades/52000.png (deflated 0%)\n",
            "  adding: content/images/facades/19500.png (deflated 0%)\n",
            "  adding: content/images/facades/97000.png (deflated 0%)\n",
            "  adding: content/images/facades/3000.png (deflated 0%)\n",
            "  adding: content/images/facades/27000.png (deflated 0%)\n",
            "  adding: content/images/facades/93000.png (deflated 0%)\n",
            "  adding: content/images/facades/101000.png (deflated 0%)\n",
            "  adding: content/images/facades/55500.png (deflated 0%)\n",
            "  adding: content/images/facades/86500.png (deflated 0%)\n",
            "  adding: content/images/facades/66000.png (deflated 0%)\n",
            "  adding: content/images/facades/7500.png (deflated 0%)\n",
            "  adding: content/images/facades/21000.png (deflated 0%)\n",
            "  adding: content/images/facades/44500.png (deflated 0%)\n",
            "  adding: content/images/facades/76000.png (deflated 0%)\n",
            "  adding: content/images/facades/95000.png (deflated 0%)\n",
            "  adding: content/images/facades/9500.png (deflated 0%)\n",
            "  adding: content/images/facades/90000.png (deflated 0%)\n",
            "  adding: content/images/facades/42000.png (deflated 0%)\n",
            "  adding: content/images/facades/35500.png (deflated 0%)\n",
            "  adding: content/images/facades/70000.png (deflated 0%)\n",
            "  adding: content/images/facades/88500.png (deflated 0%)\n",
            "  adding: content/images/facades/6500.png (deflated 0%)\n",
            "  adding: content/images/facades/500.png (deflated 0%)\n",
            "  adding: content/images/facades/63000.png (deflated 0%)\n",
            "  adding: content/images/facades/39500.png (deflated 0%)\n",
            "  adding: content/images/facades/94500.png (deflated 0%)\n",
            "  adding: content/images/facades/91000.png (deflated 0%)\n",
            "  adding: content/images/facades/51000.png (deflated 0%)\n",
            "  adding: content/images/facades/65500.png (deflated 0%)\n",
            "  adding: content/images/facades/22500.png (deflated 0%)\n",
            "  adding: content/images/facades/33000.png (deflated 0%)\n",
            "  adding: content/images/facades/93500.png (deflated 0%)\n",
            "  adding: content/images/facades/86000.png (deflated 0%)\n",
            "  adding: content/images/facades/99500.png (deflated 0%)\n",
            "  adding: content/images/facades/83500.png (deflated 0%)\n",
            "  adding: content/images/facades/82000.png (deflated 0%)\n",
            "  adding: content/images/facades/57500.png (deflated 0%)\n",
            "  adding: content/images/facades/48000.png (deflated 0%)\n",
            "  adding: content/images/facades/20500.png (deflated 0%)\n",
            "  adding: content/images/facades/73000.png (deflated 0%)\n",
            "  adding: content/images/facades/4000.png (deflated 0%)\n",
            "  adding: content/images/facades/99000.png (deflated 0%)\n",
            "  adding: content/images/facades/70500.png (deflated 0%)\n",
            "  adding: content/images/facades/45000.png (deflated 0%)\n",
            "  adding: content/images/facades/69000.png (deflated 0%)\n",
            "  adding: content/images/facades/74000.png (deflated 0%)\n",
            "  adding: content/images/facades/40500.png (deflated 0%)\n",
            "  adding: content/images/facades/28000.png (deflated 0%)\n",
            "  adding: content/images/facades/57000.png (deflated 0%)\n",
            "  adding: content/images/facades/12500.png (deflated 0%)\n",
            "  adding: content/images/facades/53500.png (deflated 0%)\n",
            "  adding: content/images/facades/59500.png (deflated 0%)\n",
            "  adding: content/images/facades/15500.png (deflated 0%)\n",
            "  adding: content/images/facades/81000.png (deflated 0%)\n",
            "  adding: content/images/facades/90500.png (deflated 0%)\n",
            "  adding: content/images/facades/78500.png (deflated 0%)\n",
            "  adding: content/images/facades/8500.png (deflated 0%)\n",
            "  adding: content/images/facades/1000.png (deflated 0%)\n",
            "  adding: content/images/facades/47500.png (deflated 0%)\n",
            "  adding: content/images/facades/5000.png (deflated 0%)\n",
            "  adding: content/images/facades/14000.png (deflated 0%)\n",
            "  adding: content/images/facades/17500.png (deflated 0%)\n",
            "  adding: content/images/facades/0.png (deflated 0%)\n",
            "  adding: content/images/facades/25500.png (deflated 0%)\n",
            "  adding: content/images/facades/72500.png (deflated 0%)\n",
            "  adding: content/images/facades/54500.png (deflated 0%)\n",
            "  adding: content/images/facades/62500.png (deflated 0%)\n",
            "  adding: content/images/facades/19000.png (deflated 0%)\n",
            "  adding: content/images/facades/28500.png (deflated 0%)\n",
            "  adding: content/images/facades/68000.png (deflated 0%)\n",
            "  adding: content/images/facades/30000.png (deflated 0%)\n",
            "  adding: content/images/facades/98000.png (deflated 0%)\n",
            "  adding: content/images/facades/87500.png (deflated 0%)\n",
            "  adding: content/images/facades/56500.png (deflated 0%)\n",
            "  adding: content/images/facades/50000.png (deflated 0%)\n",
            "  adding: content/images/facades/56000.png (deflated 0%)\n",
            "  adding: content/images/facades/46500.png (deflated 0%)\n",
            "  adding: content/images/facades/11000.png (deflated 0%)\n",
            "  adding: content/images/facades/2000.png (deflated 0%)\n",
            "  adding: content/images/facades/51500.png (deflated 0%)\n",
            "  adding: content/images/facades/96000.png (deflated 0%)\n",
            "  adding: content/images/facades/43500.png (deflated 0%)\n",
            "  adding: content/images/facades/98500.png (deflated 0%)\n",
            "  adding: content/images/facades/16000.png (deflated 0%)\n",
            "  adding: content/images/facades/64000.png (deflated 0%)\n",
            "  adding: content/images/facades/4500.png (deflated 0%)\n",
            "  adding: content/images/facades/58500.png (deflated 0%)\n",
            "  adding: content/images/facades/47000.png (deflated 0%)\n",
            "  adding: content/images/facades/80500.png (deflated 0%)\n",
            "  adding: content/images/facades/74500.png (deflated 0%)\n",
            "  adding: content/images/facades/23000.png (deflated 0%)\n",
            "  adding: content/images/facades/12000.png (deflated 0%)\n",
            "  adding: content/images/facades/63500.png (deflated 0%)\n",
            "  adding: content/images/facades/62000.png (deflated 0%)\n",
            "  adding: content/images/facades/32500.png (deflated 0%)\n",
            "  adding: content/images/facades/34000.png (deflated 0%)\n",
            "  adding: content/images/facades/59000.png (deflated 0%)\n",
            "  adding: content/images/facades/83000.png (deflated 0%)\n",
            "  adding: content/images/facades/34500.png (deflated 0%)\n",
            "  adding: content/images/facades/92000.png (deflated 0%)\n",
            "  adding: content/images/facades/16500.png (deflated 0%)\n",
            "  adding: content/images/facades/37500.png (deflated 0%)\n",
            "  adding: content/images/facades/41500.png (deflated 0%)\n",
            "  adding: content/images/facades/7000.png (deflated 0%)\n",
            "  adding: content/images/facades/10500.png (deflated 0%)\n",
            "  adding: content/images/facades/75500.png (deflated 0%)\n",
            "  adding: content/images/facades/79000.png (deflated 0%)\n",
            "  adding: content/images/facades/60000.png (deflated 0%)\n",
            "  adding: content/images/facades/61000.png (deflated 0%)\n",
            "  adding: content/images/facades/11500.png (deflated 0%)\n",
            "  adding: content/images/facades/10000.png (deflated 0%)\n",
            "  adding: content/images/facades/13000.png (deflated 0%)\n",
            "  adding: content/images/facades/85500.png (deflated 0%)\n",
            "  adding: content/images/facades/29500.png (deflated 0%)\n",
            "  adding: content/images/facades/32000.png (deflated 0%)\n",
            "  adding: content/images/facades/26000.png (deflated 0%)\n",
            "  adding: content/images/facades/5500.png (deflated 0%)\n",
            "  adding: content/images/facades/65000.png (deflated 0%)\n",
            "  adding: content/images/facades/67500.png (deflated 0%)\n",
            "  adding: content/images/facades/26500.png (deflated 0%)\n",
            "  adding: content/images/facades/58000.png (deflated 0%)\n",
            "  adding: content/images/facades/49000.png (deflated 0%)\n",
            "  adding: content/images/facades/45500.png (deflated 0%)\n",
            "  adding: content/images/facades/77000.png (deflated 0%)\n",
            "  adding: content/images/facades/22000.png (deflated 0%)\n",
            "  adding: content/images/facades/50500.png (deflated 0%)\n",
            "  adding: content/images/facades/71500.png (deflated 0%)\n",
            "  adding: content/images/facades/53000.png (deflated 0%)\n",
            "  adding: content/images/facades/96500.png (deflated 0%)\n",
            "  adding: content/images/facades/75000.png (deflated 0%)\n",
            "  adding: content/images/facades/43000.png (deflated 0%)\n",
            "  adding: content/images/facades/36500.png (deflated 0%)\n",
            "  adding: content/images/facades/29000.png (deflated 0%)\n",
            "  adding: content/images/facades/8000.png (deflated 0%)\n",
            "  adding: content/images/facades/30500.png (deflated 0%)\n",
            "  adding: content/images/facades/3500.png (deflated 0%)\n",
            "  adding: content/images/facades/85000.png (deflated 0%)\n",
            "  adding: content/images/facades/1500.png (deflated 0%)\n",
            "  adding: content/images/facades/18000.png (deflated 0%)\n",
            "  adding: content/images/facades/97500.png (deflated 0%)\n",
            "  adding: content/images/facades/100500.png (deflated 0%)\n",
            "  adding: content/images/facades/38500.png (deflated 0%)\n",
            "  adding: content/images/facades/40000.png (deflated 0%)\n",
            "  adding: content/images/facades/91500.png (deflated 0%)\n",
            "  adding: content/images/facades/87000.png (deflated 0%)\n",
            "  adding: content/images/facades/71000.png (deflated 0%)\n",
            "  adding: content/images/facades/69500.png (deflated 0%)\n",
            "  adding: content/images/facades/77500.png (deflated 0%)\n",
            "  adding: content/images/facades/42500.png (deflated 0%)\n",
            "  adding: content/images/facades/2500.png (deflated 0%)\n",
            "  adding: content/images/facades/72000.png (deflated 0%)\n",
            "  adding: content/images/facades/27500.png (deflated 0%)\n",
            "  adding: content/images/facades/88000.png (deflated 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_12acbf4f-25fb-4e62-8c89-25949dd6e1f5\", \"file.zip\", 520672738)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S70ZnnuF4yST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}